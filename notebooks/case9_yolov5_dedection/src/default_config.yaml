# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
# Url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
outputs_url: ""
# Path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
#device_target: "Ascend"
device_target: "CPU"
#need_modelarts_dataset_unzip: True
need_modelarts_dataset_unzip: False
modelarts_dataset_unzip_name: "coco"
num_parallel_workers: 1
# ==============================================================================
# Train options
#data_dir: "F:/coco"#/data/coco
data_dir: "./data/coco"
per_batch_size: 4
yolov5_version: "yolov5s"
pretrained_backbone: ""
resume_yolov5: ""
pretrained_checkpoint: ""
output_dir: "./output"
train_img_dir: "train2017"
train_json_file: "annotations/instances_train2017.json"

lr_scheduler: "cosine_annealing"
lr: 0.01
lr_epochs: "220,250"
lr_gamma: 0.1
eta_min: 0.0
T_max: 300         # please set 320 when run on 1p
max_epoch: 1     # please set 320 when run on 1p
warmup_epochs: 20  # please set 4 when run on 1p
weight_decay: 0.0005
momentum: 0.9
loss_scale: 1024
label_smooth: 0
label_smooth_factor: 0.1
log_interval: 100
ckpt_path: "outputs/"
is_distributed: 0
bind_cpu: True
device_num: 1
rank: 0
group_size: 1
need_profiler: 0
resize_rate: 10
filter_weight: False

# Eval options
pretrained: ""
log_path: "outputs/"
ann_val_file: ""
eval_nms_thresh: 0.6
ignore_threshold: 0.7
test_ignore_threshold: 0.001
multi_label: True
multi_label_thresh: 0.1

# Export options
device_id: 0
batch_size: 1
testing_shape: [640, 640]
ckpt_file: ""
file_name: "yolov5"
file_format: "MINDIR"
dataset_path: ""
ann_file: ""


# Other default config
hue: 0.015
saturation: 1.5
value: 0.4
jitter: 0.3

num_classes: 80
max_box: 150
checkpoint_filter_list: ['feature_map.back_block1.conv.weight', 'feature_map.back_block1.conv.bias',
                         'feature_map.back_block2.conv.weight', 'feature_map.back_block2.conv.bias',
                         'feature_map.back_block3.conv.weight', 'feature_map.back_block3.conv.bias']

# h->w
anchor_scales: [[12, 16],
                [19, 36],
                [40, 28],
                [36, 75],
                [76, 55],
                [72, 146],
                [142, 110],
                [192, 243],
                [459, 401]]

out_channel: 255  # 3 * (num_classes + 5)

input_shape: [[3, 32, 64, 128, 256, 512, 1],
              [3, 48, 96, 192, 384, 768, 2],
              [3, 64, 128, 256, 512, 1024, 3],
              [3, 80, 160, 320, 640, 1280, 4]]

# test_param
test_img_shape: [640, 640]

labels: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
          'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
          'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
          'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
          'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
          'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
          'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
          'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
          'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',
          'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush' ]

coco_ids: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27,
            28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53,
            54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80,
            81, 82, 84, 85, 86, 87, 88, 89, 90 ]

result_files: './result_Files'

---

# Help description for each configuration
# Train options
data_dir: "Train dataset directory."
per_batch_size: "Batch size for Training."
pretrained_backbone: "The ckpt file of CspDarkNet53."
resume_yolov5: "The ckpt file of YOLOv5, which used to fine tune."
pretrained_checkpoint: "The ckpt file of YOLOv5CspDarkNet53."
lr_scheduler: "Learning rate scheduler, options: exponential, cosine_annealing."
lr: "Learning rate."
lr_epochs: "Epoch of changing of lr changing, split with ','."
lr_gamma: "Decrease lr by a factor of exponential lr_scheduler."
eta_min: "Eta_min in cosine_annealing scheduler."
T_max: "T-max in cosine_annealing scheduler."
max_epoch: "Max epoch num to train the model."
warmup_epochs: "Warmup epochs."
weight_decay: "Weight decay factor."
momentum: "Momentum."
loss_scale: "Static loss scale."
label_smooth: "Whether to use label smooth in CE."
label_smooth_factor: "Smooth strength of original one-hot."
log_interval: "Logging interval steps."
ckpt_path: "Checkpoint save location."
ckpt_interval: "Save checkpoint interval."
is_save_on_master: "Save ckpt on master or all rank, 1 for master, 0 for all ranks."
is_distributed: "Distribute train or not, 1 for yes, 0 for no."
bind_cpu: "Whether bind cpu when distributed training."
device_num: "Device numbers per server"
rank: "Local rank of distributed."
group_size: "World size of device."
need_profiler: "Whether use profiler. 0 for no, 1 for yes."
resize_rate: "Resize rate for multi-scale training."
ann_file: "path to annotation"
each_multiscale: "Apply multi-scale for each scale"
labels: "the label of train data"
multi_label: "use multi label to nms"
multi_label_thresh: "multi label thresh"

# Eval options
pretrained: "model_path, local pretrained model to load"
log_path: "checkpoint save location"
ann_val_file: "path to annotation"

# Export options
device_id: "Device id for export"
batch_size: "batch size for export"
testing_shape: "shape for test"
ckpt_file: "Checkpoint file path for export"
file_name: "output file name for export"
file_format: "file format for export"
result_files: 'path to 310 infer result floder'
